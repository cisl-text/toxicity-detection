train:
  # earlystopping + save
  patience: 5
  delta: 0
  saveDir: "./models/finetuneRoberta"
  # MODEL
  # "./models/hateBERT
  model: "roberta-base"
  tokenizer: "roberta-base"
  # training setting
  epoch: 32
  batch_size: 4
  cuda: '2'
  lr: 0.00001
  bertadam: True
  warmup_proportion: 0.1 # defalut: 0
  weight_decay: False
  # Dataset Configuration
  dataset:
    # GabHateCorpus
    # ImplicitHateCorpus
    shuffle: False
    splitRatio: 0.8
    name: 'GabHateCorpus'
    pos_label: "toxic"
  # Loader Configuration
  num_workers: 4

  # eval_all
  evalAll: True  # If bertadam, then set correct_bias = False
